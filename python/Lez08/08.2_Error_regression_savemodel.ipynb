{"cells":[{"cell_type":"markdown","metadata":{"id":"mCbYcATfDXUk"},"source":["## Defining performance metrics on Regression\n"]},{"cell_type":"markdown","metadata":{"id":"7gBJTOduDgZj"},"source":["## Regression Evaluation Metrics\n"]},{"cell_type":"markdown","metadata":{"id":"ULl9ebn2DoDX"},"source":["Here are three common evaluation metrics for regression problems:\n","\n","Mean Absolute Error (MAE) is the mean of the absolute value of the errors:\n","\n","$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n","Mean Squared Error (MSE) is the mean of the squared errors:\n","\n","$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n","Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors:\n","\n","$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n","Comparing these metrics:\n","\n","MAE is the easiest to understand, because it's the average error.\n","MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n","RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n","All of these are loss functions, because we want to minimize them."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Mean Absolute Error (MAE)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The Mean Absolute Error (MAE) is an evaluation metric that measures the average\n","magnitude of residuals in a regression model. Residuals are simply the differences\n","between the true values of the target variable Y and its corresponding predicted\n","values.\n","\n","The MAE score provides insights into the average absolute value of residuals\n","regardless if they are positive or negative values. This is achieved by utilizing the\n","absolute function to calculate the distances between the true values and the\n","predicted values. Here is the formula for the MAE:\n","\n","MAE = Σ|Yᵢ — Ŷᵢ| ÷ n\n","\n","Where:\n","- Yᵢ = Represents the true value for the iᵗʰ sample\n","- Ŷᵢ = Represents the predicted value for iᵗʰ sample\n","- |…| = The absolute value function, i.e., the distance between two values\n","- Σ = The sum of the absolute differences over all the samples\n","- n = The total number of data samples\n","\n","To obtain the Mean Absolute Error, we compute the absolute differences between\n","the true values Yᵢ and predicted values Ŷᵢ, sum these differences, and then divide it\n","by the total number n of samples available in our dataset.\n","Unlike other metrics that involve squaring the residuals, the MAE score is linear.\n","This means that each individual residual contributes equally to the overall mean\n","score, making it less sensitive to outliers.\n","By not squaring the residuals, the MAE score retains the same unit as the target\n","variable Y, which ensures an easier interpretability. For instance, if we are\n","predicting house prices in U.S. Dollars, the Mean Absolute Error will also be\n","expressed in U.S. Dollars. This characteristic makes it a much more\n","straightforward metric for explaining the model’s performance to non-technical\n","stakeholders."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Mean Absolute Percentage Error (MAPE)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The Mean Absolute Percentage Error(MAPE) is very similar to the Mean Absolute\n","Error, but its main difference is that it expresses the average value of residuals in\n","percentage form. The formula for the MAPE score is as follows:\n","\n","MAPE = (Σ[(|Yᵢ — Ŷᵢ|) ÷ |Yᵢ|] ÷ n) * 100\n","\n","Where:\n","\n","- Yᵢ = Represents the true value for the iᵗʰ sample\n","- Ŷᵢ = Represents the predicted value for iᵗʰ sample\n","- |…| = The absolute value function, i.e., the distance between two values\n","- Σ = Is the sum of the squared differences between true and predicted values\n","- n = Is the total number of data samples\n","\n","To compute the MAPE score, we adopt a very similar approach as with the MAE\n","score. We start by taking the absolute value of the difference between the true\n","value Yᵢ and the predicted value Ŷᵢ, and then we divide it by the absolute value of\n","the true value |Yᵢ|. This gives us the individual absolute percentage error for each\n","data point. We sum these values and divide it by the total number of data points n.\n","To obtain the percentage values, we then multiply the result by 100.\n","By measuring the precision of our model as a percentage, the MAPE makes it\n","extremely easy for non-technical stakeholders to understand what it conveys. If our\n","house price prediction model has a MAPE of 4, it implies that, on average, our\n","model deviates by 4% in price prediction."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Mean Squared Error (MSE)\n","\n","The Mean Squared Error (MSE) is another extremely popular metric used to\n","evaluate regression models. Here’s its formula:\n","\n","MSE = Σ(Yᵢ — Ŷᵢ)² ÷ n\n","\n","Where:\n","- Yᵢ = Represents the true value for the iᵗʰ sample\n","- Ŷᵢ = Represents the predicted value for iᵗʰ sample\n","- (…)² = Represents the squared difference between true and predicted values\n","- Σ = Is the sum of the squared differences between true and predicted values\n","- n = Is the total number of data samples\n","\n","The MSE score is calculated by computing the differences between the true value\n","Yᵢ and predicted value Ŷᵢ. The differences are then squared, so we eliminate\n","negative residuals, and these squared differences are summed up. We then divide it\n","by the total number n of data samples.\n","By squaring the errors, we ensure that the MSE score is always greater than zero. It\n","also gives more weight to outliers to emphasize their influence on the final score.\n","This is particularly useful in situations where outliers may have a great impact on\n","final predictions.\n","It is important to notice that the MSE is not in the same unit as the true values in Y.\n","It is expressed in the square of the original unit, which can make it less intuitive to\n","interpret, specially for those who do not have a background in statistics."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Root Mean Squared Error (RMSE)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The Root Mean Squared Error (RMSE) can be seen as the standard deviation of the\n","residuals in our regression model. It is simply the square root of the MSE score,\n","and we use the same exact method of the Scikit-learn library to obtain this metric.\n","Here is its formula:\n","\n","RMSE = √(Σ(Yᵢ — Ŷᵢ)² ÷ n)\n","\n","Where:\n","- Yᵢ = Represents the true value for the iᵗʰ sample\n","- Ŷᵢ = Represents the predicted value for iᵗʰ sample\n","- (…)² = Represents the squared difference between true and predicted values\n","- Σ = Is the sum of the squared differences between true and predicted values\n","- n = Is the total number of data samples\n","- √ = Represents the square root function\n","\n","To simply explain the formula above, we obtain the squared differences between Yᵢ\n","and Ŷᵢ. We sum them up, divide by the total number n of samples, and then we\n","compute its square root value.\n","Since the squaring element is also present in the RMSE formula, this metric is also\n","sensible to outliers, and it gives more weight to larger errors.\n","Its interpretability, however, is easier than that of the MSE, since its values are\n","expressed in the same unit as the target variable Y. For instance, if we’re building a\n","regression model that predicts the daily returns of a certain stock, an RMSE value\n","of 2.8 would indicate that, on average, the predictions of the model differ 2.8%\n","from the actual daily returns, since those are given in percentage values.\n","Being it a very easy to comprehend metric, the Root Mean Square Error is\n","considered the standard evaluation metric for regression models in many fields."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Coefficient of Determination (R²)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The Coefficient of Determination ( score) is a measure that represents the\n","proportion of variance of the target variable that is explained by the independent\n","variables. It is an indication of how well our model fits to the data. The formula is\n","as follows:\n","\n","R² = 1 — [(Σ(Yᵢ — Ŷᵢ)²) ÷ (Σ(Yᵢ — Ȳ)²)]\n","\n","Where:\n","\n","- Yᵢ = Represents the true value for the iᵗʰ sample\n","- Ŷᵢ = Represents the predicted value for iᵗʰ sample\n","- Ȳ = Represents the mean of the actual values\n","- Σ = Is the sum of the squared differences between true values and predicted values, and\n","true values and the mean of the true values.\n","\n","In this formula, we calculate the ratio between the sum squared of residuals, and\n","the total sum of squares, which measures the squared distance between each\n","specific sample and the mean of all samples.\n","The R² score values tend to range between 0 and 1, although you can have negative\n","values too. Generally, a value closer to 1 implies a better-fitting model. However,\n","it’s important to consider other metrics such as MAE, MSE, MAPE, or RMSE\n","alongside R² to gain a deeper comprehension of the model’s performance, since\n","the R² alone can be misleading, considering it doesn’t inform the magnitude of\n","deviations between predicted and actual values."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Adjusted R squared\n","\n","Adjusted R² is a corrected goodness-of-fit (model accuracy) measure for linear models. It identifies the percentage of variance in the target field that is explained by the input or inputs.\n","R² tends to optimistically estimate the fit of the linear regression. It always increases as the number of effects are included in the model. Adjusted R² attempts to correct for this overestimation. Adjusted R² might decrease if a specific effect does not improve the model.\n","Adjusted R squared is calculated by dividing the residual mean square error by the total mean square error (which is the sample variance of the target field). The result is then subtracted from 1.\n","Adjusted R² is always less than or equal to R². A value of 1 indicates a model that perfectly predicts values in the target field. A value that is less than or equal to 0 indicates a model that has no predictive value. In the real world, adjusted R² lies between these values."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Which Metric is the Best?\n","\n","Overall, there is no definitive answer as to which metric is the best. Each one of the\n","metrics we have seen in this article has its own advantages and disadvantages.\n","The Mean Absolute Error (MAE) is a straightforward metric that is very easy to\n","interpret. It’s less sensitive to outliers, which can be useful in cases where extreme\n","values have a minimal impact on the overall performance.\n","\n","The Mean Absolute Percentage Error (MAPE), also offers easy interpretability by\n","expressing errors as a percentage of the true values. This feature makes it more\n","intuitive for non-technical stakeholders to grasp the performance of the model.\n","However, it’s important to note that the MAPE score can encounter issues when we\n","have zeros as true values. It is important to be cautious when using it in situations\n","where zero values are present.\n","\n","The Mean Squared Error (MSE) places a higher penalty on larger errors compared\n","to the MAE. By squaring the errors, the MSE score amplifies the impact of these\n","errors, which makes it more suitable for situations where larger errors should be\n","heavily penalized. The main drawback of the MSE score, however, is the fact that\n","its unit of measurement is different from the original data, which makes it less\n","intuitive to interpret.\n","\n","To address the issue of interpretability, the Root Mean Squared Error (RMSE)\n","retains the beneficial properties of MSE while maintaining the same unit as the\n","dependent variable Y. This characteristic makes the RMSE score much more easily\n","interpretable and allows for direct comparison with the original values, making it\n","the go-to metric.\n","\n","In addition to these metrics, the R² score provides a measure of how well the\n","model fits to the data. It is highly interpretable, making it easy to compare\n","different models among each other. However, it can be misleading when assessing\n","complex models, as it fails to account for overfitting or the model’s ability to\n","generalize to new data. To gain a deeper understanding of the model’s\n","performance, it is advisable to supplement the R² with other evaluation metrics."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>R&amp;D Spend</th>\n","      <th>Administration</th>\n","      <th>Marketing Spend</th>\n","      <th>Profit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>165349.20</td>\n","      <td>136897.80</td>\n","      <td>471784.10</td>\n","      <td>192261.83</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>162597.70</td>\n","      <td>151377.59</td>\n","      <td>443898.53</td>\n","      <td>191792.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>153441.51</td>\n","      <td>101145.55</td>\n","      <td>407934.54</td>\n","      <td>191050.39</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>144372.41</td>\n","      <td>118671.85</td>\n","      <td>383199.62</td>\n","      <td>182901.99</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>142107.34</td>\n","      <td>91391.77</td>\n","      <td>366168.42</td>\n","      <td>166187.94</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>131876.90</td>\n","      <td>99814.71</td>\n","      <td>362861.36</td>\n","      <td>156991.12</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>134615.46</td>\n","      <td>147198.87</td>\n","      <td>127716.82</td>\n","      <td>156122.51</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>130298.13</td>\n","      <td>145530.06</td>\n","      <td>323876.68</td>\n","      <td>155752.60</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>120542.52</td>\n","      <td>148718.95</td>\n","      <td>311613.29</td>\n","      <td>152211.77</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>123334.88</td>\n","      <td>108679.17</td>\n","      <td>304981.62</td>\n","      <td>149759.96</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>101913.08</td>\n","      <td>110594.11</td>\n","      <td>229160.95</td>\n","      <td>146121.95</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>100671.96</td>\n","      <td>91790.61</td>\n","      <td>249744.55</td>\n","      <td>144259.40</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>93863.75</td>\n","      <td>127320.38</td>\n","      <td>249839.44</td>\n","      <td>141585.52</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>91992.39</td>\n","      <td>135495.07</td>\n","      <td>252664.93</td>\n","      <td>134307.35</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>119943.24</td>\n","      <td>156547.42</td>\n","      <td>256512.92</td>\n","      <td>132602.65</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>114523.61</td>\n","      <td>122616.84</td>\n","      <td>261776.23</td>\n","      <td>129917.04</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>78013.11</td>\n","      <td>121597.55</td>\n","      <td>264346.06</td>\n","      <td>126992.93</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>94657.16</td>\n","      <td>145077.58</td>\n","      <td>282574.31</td>\n","      <td>125370.37</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>91749.16</td>\n","      <td>114175.79</td>\n","      <td>294919.57</td>\n","      <td>124266.90</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>86419.70</td>\n","      <td>153514.11</td>\n","      <td>0.00</td>\n","      <td>122776.86</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>76253.86</td>\n","      <td>113867.30</td>\n","      <td>298664.47</td>\n","      <td>118474.03</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>78389.47</td>\n","      <td>153773.43</td>\n","      <td>299737.29</td>\n","      <td>111313.02</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>73994.56</td>\n","      <td>122782.75</td>\n","      <td>303319.26</td>\n","      <td>110352.25</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>67532.53</td>\n","      <td>105751.03</td>\n","      <td>304768.73</td>\n","      <td>108733.99</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>77044.01</td>\n","      <td>99281.34</td>\n","      <td>140574.81</td>\n","      <td>108552.04</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>64664.71</td>\n","      <td>139553.16</td>\n","      <td>137962.62</td>\n","      <td>107404.34</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>75328.87</td>\n","      <td>144135.98</td>\n","      <td>134050.07</td>\n","      <td>105733.54</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>72107.60</td>\n","      <td>127864.55</td>\n","      <td>353183.81</td>\n","      <td>105008.31</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>66051.52</td>\n","      <td>182645.56</td>\n","      <td>118148.20</td>\n","      <td>103282.38</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>65605.48</td>\n","      <td>153032.06</td>\n","      <td>107138.38</td>\n","      <td>101004.64</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>61994.48</td>\n","      <td>115641.28</td>\n","      <td>91131.24</td>\n","      <td>99937.59</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>61136.38</td>\n","      <td>152701.92</td>\n","      <td>88218.23</td>\n","      <td>97483.56</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>63408.86</td>\n","      <td>129219.61</td>\n","      <td>46085.25</td>\n","      <td>97427.84</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>55493.95</td>\n","      <td>103057.49</td>\n","      <td>214634.81</td>\n","      <td>96778.92</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>46426.07</td>\n","      <td>157693.92</td>\n","      <td>210797.67</td>\n","      <td>96712.80</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>46014.02</td>\n","      <td>85047.44</td>\n","      <td>205517.64</td>\n","      <td>96479.51</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>28663.76</td>\n","      <td>127056.21</td>\n","      <td>201126.82</td>\n","      <td>90708.19</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>44069.95</td>\n","      <td>51283.14</td>\n","      <td>197029.42</td>\n","      <td>89949.14</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>20229.59</td>\n","      <td>65947.93</td>\n","      <td>185265.10</td>\n","      <td>81229.06</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>38558.51</td>\n","      <td>82982.09</td>\n","      <td>174999.30</td>\n","      <td>81005.76</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>28754.33</td>\n","      <td>118546.05</td>\n","      <td>172795.67</td>\n","      <td>78239.91</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>27892.92</td>\n","      <td>84710.77</td>\n","      <td>164470.71</td>\n","      <td>77798.83</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>23640.93</td>\n","      <td>96189.63</td>\n","      <td>148001.11</td>\n","      <td>71498.49</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>15505.73</td>\n","      <td>127382.30</td>\n","      <td>35534.17</td>\n","      <td>69758.98</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>22177.74</td>\n","      <td>154806.14</td>\n","      <td>28334.72</td>\n","      <td>65200.33</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>1000.23</td>\n","      <td>124153.04</td>\n","      <td>1903.93</td>\n","      <td>64926.08</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>1315.46</td>\n","      <td>115816.21</td>\n","      <td>297114.46</td>\n","      <td>49490.75</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>0.00</td>\n","      <td>135426.92</td>\n","      <td>0.00</td>\n","      <td>42559.73</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>542.05</td>\n","      <td>51743.15</td>\n","      <td>0.00</td>\n","      <td>35673.41</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.00</td>\n","      <td>116983.80</td>\n","      <td>45173.06</td>\n","      <td>14681.40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    R&D Spend  Administration  Marketing Spend     Profit\n","0   165349.20       136897.80        471784.10  192261.83\n","1   162597.70       151377.59        443898.53  191792.06\n","2   153441.51       101145.55        407934.54  191050.39\n","3   144372.41       118671.85        383199.62  182901.99\n","4   142107.34        91391.77        366168.42  166187.94\n","5   131876.90        99814.71        362861.36  156991.12\n","6   134615.46       147198.87        127716.82  156122.51\n","7   130298.13       145530.06        323876.68  155752.60\n","8   120542.52       148718.95        311613.29  152211.77\n","9   123334.88       108679.17        304981.62  149759.96\n","10  101913.08       110594.11        229160.95  146121.95\n","11  100671.96        91790.61        249744.55  144259.40\n","12   93863.75       127320.38        249839.44  141585.52\n","13   91992.39       135495.07        252664.93  134307.35\n","14  119943.24       156547.42        256512.92  132602.65\n","15  114523.61       122616.84        261776.23  129917.04\n","16   78013.11       121597.55        264346.06  126992.93\n","17   94657.16       145077.58        282574.31  125370.37\n","18   91749.16       114175.79        294919.57  124266.90\n","19   86419.70       153514.11             0.00  122776.86\n","20   76253.86       113867.30        298664.47  118474.03\n","21   78389.47       153773.43        299737.29  111313.02\n","22   73994.56       122782.75        303319.26  110352.25\n","23   67532.53       105751.03        304768.73  108733.99\n","24   77044.01        99281.34        140574.81  108552.04\n","25   64664.71       139553.16        137962.62  107404.34\n","26   75328.87       144135.98        134050.07  105733.54\n","27   72107.60       127864.55        353183.81  105008.31\n","28   66051.52       182645.56        118148.20  103282.38\n","29   65605.48       153032.06        107138.38  101004.64\n","30   61994.48       115641.28         91131.24   99937.59\n","31   61136.38       152701.92         88218.23   97483.56\n","32   63408.86       129219.61         46085.25   97427.84\n","33   55493.95       103057.49        214634.81   96778.92\n","34   46426.07       157693.92        210797.67   96712.80\n","35   46014.02        85047.44        205517.64   96479.51\n","36   28663.76       127056.21        201126.82   90708.19\n","37   44069.95        51283.14        197029.42   89949.14\n","38   20229.59        65947.93        185265.10   81229.06\n","39   38558.51        82982.09        174999.30   81005.76\n","40   28754.33       118546.05        172795.67   78239.91\n","41   27892.92        84710.77        164470.71   77798.83\n","42   23640.93        96189.63        148001.11   71498.49\n","43   15505.73       127382.30         35534.17   69758.98\n","44   22177.74       154806.14         28334.72   65200.33\n","45    1000.23       124153.04          1903.93   64926.08\n","46    1315.46       115816.21        297114.46   49490.75\n","47       0.00       135426.92             0.00   42559.73\n","48     542.05        51743.15             0.00   35673.41\n","49       0.00       116983.80         45173.06   14681.40"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","path = \"https://frenzy86.s3.eu-west-2.amazonaws.com/python/data/Startup.csv\"\n","df = pd.read_csv(path)\n","df"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KwjK57hMWrhC"},"outputs":[],"source":["## 1 - Declare Features and target\n","X = df.drop(columns='Profit')\n","y = df['Profit']"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1Xn2nUzPDMa1"},"outputs":[],"source":["## 2 -suddividere il problema in Training e Test\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                                    test_size = 0.2, \n","                                                    random_state = 667\n","                                                    )"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":542,"status":"ok","timestamp":1683015157271,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"},"user_tz":-120},"id":"lEQdCz9eXKsD","outputId":"f9fe6f54-2574-42e8-e4b7-3cf7471fd684"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["## 3 - Creare ed allenare il modello (fit) sulla parte di training\n","from sklearn.linear_model import LinearRegression\n","\n","model = LinearRegression()\n","model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"P5TI-e8JXM_A"},"outputs":[],"source":["## 4 - creare la predizione sulla parte di TEST\n","y_pred = model.predict(X_test) #on Test set"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683016520281,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"},"user_tz":-120},"id":"UXA4NomrDMV2","outputId":"09783a22-3f6a-4f66-f378-3fde5706f7ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE:  6863.327578772788\n","MSE:  81932298.4533166\n","RMSE:  9051.646173670102\n","R2_score:  0.9441590602423614\n","Adjusted_R2_score:  0.9162385903635422\n"]}],"source":["## 5 -  Misurare l'errore del mio modello\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = mean_squared_error(y_test, y_pred, squared=False)\n","r2score = r2_score(y_test, y_pred)\n","ad_r2score = 1-(1-r2score)*(len(X_test)-1)/(len(X_test)-X_test.shape[1]-1)\n","\n","print('MAE: ', mae)\n","print('MSE: ', mse)\n","print('RMSE: ', rmse)\n","print('R2_score: ', r2score)\n","print('Adjusted_R2_score: ', ad_r2score)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682930229477,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"},"user_tz":-120},"id":"tfqHRZihYDs9","outputId":"24f816de-5b3a-4454-c9a9-80f73c78874b"},"outputs":[{"data":{"text/plain":["46990.028023760206"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model.predict([[324,34,56]])[0]"]},{"cell_type":"markdown","metadata":{"id":"wlsCxfJQdcz6"},"source":["<img src=\"https://frenzy86.s3.eu-west-2.amazonaws.com/python/savemodel.png\" width=600>"]},{"cell_type":"markdown","metadata":{"id":"PdzI0b-9a4K3"},"source":["## JOBLIB\n","<img src='https://frenzy86.s3.eu-west-2.amazonaws.com/python/joblib.png' widht=2000>"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1683015772214,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"},"user_tz":-120},"id":"Nhs3UNWUYIcz","outputId":"26578018-c331-4f0a-c52f-8dad4221a03e"},"outputs":[{"data":{"text/plain":["['regression_test.pkl']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import joblib\n","\n","## to save a model\n","joblib.dump(model,'regression_test.pkl')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682930232120,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"},"user_tz":-120},"id":"3dmzhEqJdzdw","outputId":"63eb7474-6f77-4d96-cc20-36476b130941"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["## to load model\n","newmodel = joblib.load('regression_test.pkl')\n","newmodel"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682930234504,"user":{"displayName":"T3Lab Vision","userId":"14779383426442114373"},"user_tz":-120},"id":"9cxvEmvaeCgh","outputId":"b9541974-002c-4355-f26d-ab9e90d87c2d"},"outputs":[{"data":{"text/plain":["46990.028023760206"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["newmodel.predict([[324,34,56]])[0]"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
